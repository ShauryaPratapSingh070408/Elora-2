{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShauryaPratapSingh070408/Elora-2/blob/main/ELORA_IMAGE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# **Elora: The Visual Mind of Nexus AI**\n",
        "\n",
        "Elora is the visual creation model of the **Nexus AI** system. It is designed to turn human ideas, words, and imagination into stunning images and videos.\n",
        "\n",
        "### **The Essence of Elora**\n",
        "The name â€œEloraâ€ represents light, creativity, imagination, and visual beauty. It sounds soft and artistic, matching its role as a creative AI partner.\n",
        "\n",
        "### **System Structure**\n",
        "*   **Nexus** â†’ Core Intelligence\n",
        "*   **Elora** â†’ Visual Generation Model\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "capabilities"
      },
      "source": [
        "### **Eloraâ€™s Main Capabilities**\n",
        "*   **Convert text into images**\n",
        "*   **Convert text into videos**\n",
        "*   **Create visual stories from ideas**\n",
        "*   **Focus on creativity and artistic output**\n",
        "\n",
        "**Simple Flow:** Words â†’ Meaning â†’ Visual Design â†’ Final Image or Video\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_header"
      },
      "source": [
        "## **ğŸš€ Launch Elora**\n",
        "Click the play button below to initialize the Elora visual generation engine. This process will set up the environment, apply the **Pill-Shaped Glassmorphic Watermark**, and provide you with a link to the creative interface."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b0e98bb-ca88-4d1d-da60-68e6f967a9df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1: Installing dependencies...\n",
            "Collecting pygit2==1.15.1\n",
            "  Downloading pygit2-1.15.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: cffi>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from pygit2==1.15.1) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.16.0->pygit2==1.15.1) (2.23)\n",
            "Downloading pygit2-1.15.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m129.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pygit2\n",
            "  Attempting uninstall: pygit2\n",
            "    Found existing installation: pygit2 1.19.1\n",
            "    Uninstalling pygit2-1.19.1:\n",
            "      Successfully uninstalled pygit2-1.19.1\n",
            "Successfully installed pygit2-1.15.1\n",
            "Step 2: Cloning Elora Core...\n",
            "/content\n",
            "Cloning into 'Fooocus'...\n",
            "remote: Enumerating objects: 6735, done.\u001b[K\n",
            "remote: Total 6735 (delta 0), reused 0 (delta 0), pack-reused 6735 (from 1)\u001b[K\n",
            "Receiving objects: 100% (6735/6735), 33.35 MiB | 16.53 MiB/s, done.\n",
            "Resolving deltas: 100% (3849/3849), done.\n",
            "Step 3: Applying Glassmorphic Adaptive Watermark...\n",
            "Step 4: Launching Elora Engine...\n",
            "/content/Fooocus\n",
            "Already up-to-date\n",
            "Update succeeded.\n",
            "[System ARGV] ['entry_with_update.py', '--share', '--always-high-vram']\n",
            "/content/Fooocus/build_launcher.py:9: SyntaxWarning: invalid escape sequence '\\p'\n",
            "  .\\python_embeded\\python.exe -s Fooocus\\entry_with_update.py {cmds} %*\n",
            "Python 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
            "Fooocus version: 2.5.5\n",
            "Error checking version for torchsde: No package metadata was found for torchsde\n",
            "Installing requirements\n",
            "[Cleanup] Attempting to delete content of temp dir /tmp/fooocus\n",
            "[Cleanup] Cleanup successful\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/xlvaeapp.pth\" to /content/Fooocus/models/vae_approx/xlvaeapp.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 702kB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/vaeapp_sd15.pt\" to /content/Fooocus/models/vae_approx/vaeapp_sd15.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 715kB/s]\n",
            "Downloading: \"https://huggingface.co/mashb1t/misc/resolve/main/xl-to-v1_interposer-v4.0.safetensors\" to /content/Fooocus/models/vae_approx/xl-to-v1_interposer-v4.0.safetensors\n",
            "\n",
            "100% 5.40M/5.40M [00:00<00:00, 12.6MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_expansion.bin\" to /content/Fooocus/models/prompt_expansion/fooocus_expansion/pytorch_model.bin\n",
            "\n",
            "100% 335M/335M [00:02<00:00, 118MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/juggernautXL_v8Rundiffusion.safetensors\" to /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "\n",
            "100% 6.62G/6.62G [01:26<00:00, 82.2MB/s]\n",
            "Downloading: \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors\" to /content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors\n",
            "\n",
            "100% 47.3M/47.3M [00:00<00:00, 50.3MB/s]\n",
            "Total VRAM 15095 MB, total RAM 12976 MB\n",
            "Set vram state to: HIGH_VRAM\n",
            "Always offload VRAM\n",
            "Device: cuda:0 Tesla T4 : native\n",
            "VAE dtype: torch.float32\n",
            "Using pytorch cross attention\n",
            "/content/Fooocus/ldm_patched/unipc/uni_pc.py:56: SyntaxWarning: invalid escape sequence '\\h'\n",
            "  The `alphas_cumprod` is the \\hat{alpha_n} arrays in the notations of DDPM. Specifically, DDPMs assume that\n",
            "Refiner unloaded.\n",
            "Running on local URL:  http://127.0.0.1:7865\n",
            "IMPORTANT: You are using gradio version 3.41.2, however version 4.44.1 is available, please upgrade.\n",
            "--------\n",
            "model_type EPS\n",
            "UNet ADM Dimension 2816\n",
            "Running on public URL: https://2d9b341015ea17a92c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Using pytorch attention in VAE\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "Using pytorch attention in VAE\n",
            "extra {'cond_stage_model.clip_l.logit_scale', 'cond_stage_model.clip_l.text_projection'}\n",
            "left over keys: dict_keys(['cond_stage_model.clip_l.transformer.text_model.embeddings.position_ids'])\n",
            "loaded straight to GPU\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "Base model loaded: /content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "VAE loaded: None\n",
            "Request to load LoRAs [('sd_xl_offset_example-lora_1.0.safetensors', 0.1)] for model [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors].\n",
            "Loaded LoRA [/content/Fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors] for UNet [/content/Fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors] with 788 keys at weight 0.1.\n",
            "Fooocus V2 Expansion: Vocab with 642 words.\n",
            "Fooocus Expansion engine loaded for cuda:0, use_fp16 = True.\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.58 seconds\n",
            "2026-01-28 08:33:56.669819: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1769589236.882531    1271 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1769589236.942925    1271 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1769589237.374217    1271 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769589237.374253    1271 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769589237.374258    1271 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1769589237.374265    1271 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-28 08:33:57.417521: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Started worker with PID 318\n",
            "App started successful. Use the app with http://127.0.0.1:7865/ or 127.0.0.1:7865 or https://2d9b341015ea17a92c.gradio.live\n",
            "[Parameters] Adaptive CFG = 7\n",
            "[Parameters] CLIP Skip = 2\n",
            "[Parameters] Sharpness = 2\n",
            "[Parameters] ControlNet Softness = 0.25\n",
            "[Parameters] ADM Scale = 1.5 : 0.8 : 0.3\n",
            "[Parameters] Seed = 5418496493834866230\n",
            "[Parameters] CFG = 4\n",
            "[Fooocus] Loading control models ...\n",
            "[Parameters] Sampler = dpmpp_2m_sde_gpu - karras\n",
            "[Parameters] Steps = 30 - 15\n",
            "[Fooocus] Initializing ...\n",
            "[Fooocus] Loading models ...\n",
            "Refiner unloaded.\n",
            "[Fooocus] Processing prompts ...\n",
            "[Fooocus] Preparing Fooocus text #1 ...\n",
            "[Prompt Expansion] a cat, intricate, elegant, highly detailed, wonderful colors, glowing, sharp focus, magnificent, thought, cinematic, dramatic ambient, professional, artistic, singular, best, unique, beautiful, cute, inspiring, gorgeous, creative, positive, shiny, vibrant, attractive, confident, pretty, determined, passionate, cool, friendly, futuristic, draped, lovely, flowing\n",
            "[Fooocus] Preparing Fooocus text #2 ...\n",
            "[Prompt Expansion] a cat, deep focus, beautiful, highly detailed, elegant, bright colors, intricate, dramatic light, sharp, phenomenal fine detail, pretty background, professional, cinematic, elaborate best, expressive, symmetry, thought, iconic, cute, perfect composition, shiny, polished, colorful, complex, color, great, atmosphere, luxury, glowing, rich vivid, focused, clear\n",
            "[Fooocus] Encoding positive #1 ...\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.11 seconds\n",
            "[Fooocus] Encoding positive #2 ...\n",
            "[Fooocus] Encoding negative #1 ...\n",
            "[Fooocus] Encoding negative #2 ...\n",
            "[Parameters] Denoising Strength = 1.0\n",
            "[Parameters] Initial Latent shape: Image Space (896, 1152)\n",
            "Preparation time: 3.41 seconds\n",
            "Using karras scheduler.\n",
            "[Fooocus] Preparing task 1/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 1.50 seconds\n",
            "100% 30/30 [00:25<00:00,  1.18it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.28 seconds\n",
            "[Fooocus] Saving image 1/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2026-01-28/log.html\n",
            "Generating and saving time: 29.98 seconds\n",
            "[Fooocus] Preparing task 2/2 ...\n",
            "[Sampler] refiner_swap_method = joint\n",
            "[Sampler] sigma_min = 0.0291671771556139, sigma_max = 14.614643096923828\n",
            "Requested to load SDXL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.60 seconds\n",
            "100% 30/30 [00:25<00:00,  1.18it/s]\n",
            "Requested to load AutoencoderKL\n",
            "Loading 1 new model\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.27 seconds\n",
            "[Fooocus] Saving image 2/2 to system ...\n",
            "Image generated with private log at: /content/Fooocus/outputs/2026-01-28/log.html\n",
            "Generating and saving time: 29.09 seconds\n",
            "[Enhance] Skipping, preconditions aren't met\n",
            "Processing time (total): 59.07 seconds\n",
            "Requested to load SDXLClipModel\n",
            "Requested to load GPT2LMHeadModel\n",
            "Loading 2 new models\n",
            "Total time: 73.00 seconds\n",
            "[Fooocus Model Management] Moving model(s) has taken 0.80 seconds\n"
          ]
        }
      ],
      "source": [
        "#@title Initialize Elora Engine\n",
        "import os\n",
        "\n",
        "print(\"Step 1: Installing dependencies...\")\n",
        "!pip install pygit2==1.15.1\n",
        "\n",
        "print(\"Step 2: Cloning Elora Core...\")\n",
        "%cd /content\n",
        "if not os.path.exists('/content/Fooocus'):\n",
        "    !git clone https://github.com/lllyasviel/Fooocus.git\n",
        "\n",
        "print(\"Step 3: Applying Glassmorphic Adaptive Watermark...\")\n",
        "patch_code = r\"\"\"\n",
        "import os\n",
        "from PIL import Image, ImageDraw, ImageFont, ImageFilter\n",
        "\n",
        "def patch_private_logger():\n",
        "    file_path = '/content/Fooocus/modules/private_logger.py'\n",
        "    if not os.path.exists(file_path): return\n",
        "    with open(file_path, 'r', encoding='utf-8') as f: lines = f.readlines()\n",
        "    if any('Nexus â€¢ Elora' in line for line in lines): return\n",
        "\n",
        "    new_lines = []\n",
        "    import_added = False\n",
        "    for line in lines:\n",
        "        new_lines.append(line)\n",
        "        if 'from PIL import Image' in line and not import_added:\n",
        "            new_lines.append('from PIL import ImageDraw, ImageFont, ImageFilter\\n')\n",
        "            import_added = True\n",
        "        if 'image = Image.fromarray(img)' in line:\n",
        "            new_lines.extend([\n",
        "                '    try:\\n',\n",
        "                '        w, h = image.size\\n',\n",
        "                '        f_size = max(18, int(h * 0.025))\\n',\n",
        "                '        try: font = ImageFont.truetype(\"/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf\", f_size)\\n',\n",
        "                '        except: font = ImageFont.load_default()\\n',\n",
        "                '        txt = \"Nexus â€¢ Elora\"\\n',\n",
        "                '        try: bbox = ImageDraw.Draw(Image.new(\"L\", (1,1))).textbbox((0, 0), txt, font=font); tw, th = bbox[2]-bbox[0], bbox[3]-bbox[1]\\n',\n",
        "                '        except: tw, th = ImageDraw.Draw(Image.new(\"L\", (1,1))).textsize(txt, font=font)\\n',\n",
        "                '        px, py = int(f_size * 1.2), int(f_size * 0.6); rw, rh = tw + px*2, th + py*2\\n',\n",
        "                '        rad = rh // 2; mx = int(h * 0.03); rx, ry = w - rw - mx, h - rh - mx\\n',\n",
        "                '        mask = Image.new(\"L\", (rw, rh), 0); ImageDraw.Draw(mask).rounded_rectangle([0, 0, rw, rh], radius=rad, fill=255)\\n',\n",
        "                '        reg = image.crop((rx, ry, rx + rw, ry + rh)).convert(\"RGBA\")\\n',\n",
        "                '        blur = reg.filter(ImageFilter.GaussianBlur(radius=15))\\n',\n",
        "                '        ovl = Image.new(\"RGBA\", (rw, rh), (255, 255, 255, 40))\\n',\n",
        "                '        fros = Image.alpha_composite(blur, ovl)\\n',\n",
        "                '        fin = Image.new(\"RGBA\", (rw, rh), (0, 0, 0, 0)); fin.paste(fros, (0, 0), mask)\\n',\n",
        "                '        image = image.convert(\"RGBA\"); image.alpha_composite(fin, (rx, ry))\\n',\n",
        "                '        draw = ImageDraw.Draw(image)\\n',\n",
        "                '        draw.rounded_rectangle([rx, ry, rx + rw, ry + rh], radius=rad, outline=(255, 255, 255, 80), width=1)\\n',\n",
        "                '        draw.text((rx + px, ry + py - int(th * 0.1)), txt, font=font, fill=(255, 255, 255, 230))\\n',\n",
        "                '        image = image.convert(\"RGB\")\\n',\n",
        "                '    except: pass\\n'\n",
        "            ])\n",
        "    with open(file_path, 'w', encoding='utf-8') as f: f.writelines(new_lines)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    patch_private_logger()\n",
        "\"\"\"\n",
        "with open('/content/patch_elora.py', 'w') as f: f.write(patch_code)\n",
        "!python /content/patch_elora.py\n",
        "\n",
        "print(\"Step 4: Launching Elora Engine...\")\n",
        "%cd /content/Fooocus\n",
        "!python entry_with_update.py --share --always-high-vram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "about_developer"
      },
      "source": [
        "---\n",
        "## **ğŸ‘¤ About the Developer**\n",
        "**Elora** is part of the **Nexus AI** project, developed by **Shaurya Pratap Singh**.\n",
        "\n",
        "### **Developer Vision**\n",
        "Shaurya Pratap Singh is building Nexus and Elora to make AI:\n",
        "*   **Creative**, not mechanical\n",
        "*   **Simple**, not confusing\n",
        "*   **Powerful**, but friendly to use\n",
        "\n",
        "The goal is to help people create visuals without needing complex tools or deep technical knowledge. Elora is not just a tool; it is designed to feel like a creative partner that turns ideas into visual stories."
      ]
    }
  ]
}